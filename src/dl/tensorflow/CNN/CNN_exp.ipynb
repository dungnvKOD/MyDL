{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AlexNet \n",
    "đọc tài liệu  https://www.phamduytung.com/blog/2018-06-15-understanding-alexnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets('tmp/data/',one_hot=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "num_step=200\n",
    "batch_size=128\n",
    "display=10\n",
    "\n",
    "# Network parameters\n",
    "\n",
    "num_input=784\n",
    "num_class=10\n",
    "dropout=0.25\n",
    "\n",
    "# tf Grapd\n",
    "X=tf.placeholder(tf.float32,[None,num_input])\n",
    "y=tf.placeholder(tf.float32,[None,num_class])\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "\n",
    "def conv2d(x,w,b,strider=1):\n",
    "    x=tf.nn.conv2d(x,w,strides=[1,strider,strider,1],padding='SAME')\n",
    "    x=tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x,k=2):\n",
    "    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
    "\n",
    "# Create model\n",
    "def conv_net(x,dropout):\n",
    "    \n",
    "    weights={\n",
    "        # filter=11 ,input=3 ,output=96\n",
    "        'w1':tf.Variable(tf.random_normal([11,11,1,96])),\n",
    "        'w2':tf.Variable(tf.random_normal([5,5,96,256])),\n",
    "        'w3':tf.Variable(tf.random_normal([3,3,256,384])),\n",
    "        'w4':tf.Variable(tf.random_normal([3,3,384,384])),\n",
    "        'w5':tf.Variable(tf.random_normal([3,3,384,256])),\n",
    "        'wd1':tf.Variable(tf.random_normal([1*1*256,4096])),\n",
    "        'wd2':tf.Variable(tf.random_normal([4096,4096])),\n",
    "        'wd3':tf.Variable(tf.random_normal([4096,num_class]))\n",
    "        \n",
    "    }\n",
    "    biases={\n",
    "        'b1':tf.Variable(tf.random_normal([96])),\n",
    "        'b2':tf.Variable(tf.random_normal([256])),\n",
    "        'b3':tf.Variable(tf.random_normal([384])),\n",
    "        'b4':tf.Variable(tf.random_normal([384])),\n",
    "        'b5':tf.Variable(tf.random_normal([256])),\n",
    "        'bd1':tf.Variable(tf.random_normal([4096])),\n",
    "        'bd2':tf.Variable(tf.random_normal([4096])),\n",
    "        'bd3':tf.Variable(tf.random_normal([num_class]))  \n",
    "    }\n",
    "    \n",
    "    x=tf.reshape(x,shape=[-1,28,28,1])\n",
    "    conv1=conv2d(x,weights['w1'],biases['b1'],strider=4)\n",
    "    conv1= maxpool2d(conv1,k=3)\n",
    "    \n",
    "    conv2=conv2d(conv1,weights['w2'],biases['b2'],strider=1)\n",
    "    conv2=maxpool2d(conv2,k=3)\n",
    "    \n",
    "    conv3=conv2d(conv2,weights['w3'],biases['b3'],strider=1)\n",
    "    \n",
    "    conv4=conv2d(conv3,weights['w4'],biases['b4'],strider=1)\n",
    "    conv4=maxpool2d(conv4,k=1)\n",
    "    \n",
    "    conv5=conv2d(conv4,weights['w5'],biases['b5'],strider=1)\n",
    "    conv5=maxpool2d(conv5,k=1)\n",
    "    \n",
    "    # Flatten the multi-dimensional output to feed fully connected layer\n",
    "    \n",
    "    feature_map=tf.reshape(conv5,shape=[-1,weights['wd1'].get_shape().as_list()[0]])\n",
    "    \n",
    "    # Fully connected layer | Dropout\n",
    "    \n",
    "    fc_layer_1=tf.matmul(feature_map,weights['wd1']+biases['bd1'])\n",
    "    fc_layer_1=tf.nn.dropout(fc_layer_1,dropout)\n",
    "    \n",
    "    fc_layer_2=tf.matmul(fc_layer_1,weights['wd2']+biases['bd2'])\n",
    "    fc_layer_2=tf.nn.dropout(fc_layer_2,dropout)\n",
    "    \n",
    "    output=tf.matmul(fc_layer_2,weights['wd3']+biases['bd3'])\n",
    "    \n",
    "    return output\n",
    "\n",
    "logits=conv_net(X,keep_prob)\n",
    "prediction=tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "\n",
    "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# START TRAINING\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1,num_step+1):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer,feed_dict={X:batch_x,y:batch_y,keep_prob:0.8})\n",
    "        if step%display==0 or step==1:\n",
    "            loss,acc=sess.run([loss_op,accuracy],feed_dict={\n",
    "                X:batch_x,\n",
    "                y:batch_y,\n",
    "                keep_prob:1.0\n",
    "            })\n",
    "        \n",
    "    print(\"ok.....\")\n",
    "#     sess.run(accuracy,feed_dict={X:mnist.test.images[:256],\n",
    "#                                  y:mnist.test.labels[:256],\n",
    "#                                  keep_prob:1.0})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}