{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_exp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dungnvKOD/MyDL/blob/master/src/dl/tensorflow/CNN/CNN_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pMUaa3dJ3ISj",
        "colab_type": "text"
      },
      "source": [
        "## AlexNet \n",
        "đọc tài liệu  https://www.phamduytung.com/blog/2018-06-15-understanding-alexnet/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z1ZrM8903ISm",
        "colab_type": "code",
        "outputId": "c1a36e61-1bf8-4ab3-a4ff-2b5fb071c263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist=input_data.read_data_sets('tmp/data/',one_hot=True)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-be0e27bda5d2>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting tmp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vr1d79Gf3ISp",
        "colab_type": "code",
        "outputId": "52638d85-be35-4f27-8212-0c7638eeb721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "learning_rate=0.01\n",
        "num_step=20\n",
        "batch_size=128\n",
        "display=10\n",
        "\n",
        "# Network parameters\n",
        "\n",
        "num_input=784\n",
        "num_class=10\n",
        "dropout=0.25\n",
        "\n",
        "# tf Grapd\n",
        "X=tf.placeholder(tf.float32,[None,num_input])\n",
        "y=tf.placeholder(tf.float32,[None,num_class])\n",
        "keep_prob=tf.placeholder(tf.float32)\n",
        "\n",
        "def conv2d(x,w,b,strider=1):\n",
        "    x=tf.nn.conv2d(x,w,strides=[1,strider,strider,1],padding='SAME')\n",
        "    x=tf.nn.bias_add(x,b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "def maxpool2d(x,k=2):\n",
        "    return tf.nn.max_pool(x,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
        "\n",
        "# Create model\n",
        "def conv_net(x,dropout):\n",
        "    \n",
        "    weights={\n",
        "        # filter=11 ,input=3 ,output=96\n",
        "        'w1':tf.Variable(tf.random_normal([11,11,1,96])),\n",
        "        'w2':tf.Variable(tf.random_normal([5,5,96,256])),\n",
        "        'w3':tf.Variable(tf.random_normal([3,3,256,384])),\n",
        "        'w4':tf.Variable(tf.random_normal([3,3,384,384])),\n",
        "        'w5':tf.Variable(tf.random_normal([3,3,384,256])),\n",
        "        'wd1':tf.Variable(tf.random_normal([1*1*256,4096])),\n",
        "        'wd2':tf.Variable(tf.random_normal([4096,4096])),\n",
        "        'wd3':tf.Variable(tf.random_normal([4096,num_class]))\n",
        "        \n",
        "    }\n",
        "    biases={\n",
        "        'b1':tf.Variable(tf.random_normal([96])),\n",
        "        'b2':tf.Variable(tf.random_normal([256])),\n",
        "        'b3':tf.Variable(tf.random_normal([384])),\n",
        "        'b4':tf.Variable(tf.random_normal([384])),\n",
        "        'b5':tf.Variable(tf.random_normal([256])),\n",
        "        'bd1':tf.Variable(tf.random_normal([4096])),\n",
        "        'bd2':tf.Variable(tf.random_normal([4096])),\n",
        "        'bd3':tf.Variable(tf.random_normal([num_class]))  \n",
        "    }\n",
        "    \n",
        "    x=tf.reshape(x,shape=[-1,28,28,1])\n",
        "    conv1=conv2d(x,weights['w1'],biases['b1'],strider=4)\n",
        "    conv1= maxpool2d(conv1,k=3)\n",
        "    \n",
        "    conv2=conv2d(conv1,weights['w2'],biases['b2'],strider=1)\n",
        "    conv2=maxpool2d(conv2,k=3)\n",
        "    \n",
        "    conv3=conv2d(conv2,weights['w3'],biases['b3'],strider=1)\n",
        "    \n",
        "    conv4=conv2d(conv3,weights['w4'],biases['b4'],strider=1)\n",
        "    conv4=maxpool2d(conv4,k=1)\n",
        "    \n",
        "    conv5=conv2d(conv4,weights['w5'],biases['b5'],strider=1)\n",
        "    conv5=maxpool2d(conv5,k=1)\n",
        "    print(conv5)\n",
        "    \n",
        "    # Flatten the multi-dimensional output to feed fully connected layer\n",
        "    \n",
        "    feature_map=tf.reshape(conv5,shape=[-1,1*1*256])\n",
        "    \n",
        "    # Fully connected layer | Dropout\n",
        "    \n",
        "    fc_layer_1=tf.matmul(feature_map,weights['wd1']+biases['bd1'])\n",
        "    fc_layer_1=tf.nn.dropout(fc_layer_1,dropout)\n",
        "    \n",
        "    fc_layer_2=tf.matmul(fc_layer_1,weights['wd2']+biases['bd2'])\n",
        "    fc_layer_2=tf.nn.dropout(fc_layer_2,dropout)\n",
        "    \n",
        "    output=tf.matmul(fc_layer_2,weights['wd3']+biases['bd3'])\n",
        "    \n",
        "    return output\n",
        "\n",
        "logits=conv_net(X,keep_prob)\n",
        "prediction=tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "\n",
        "loss_op=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y))\n",
        "optimizer=tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
        "\n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "# START TRAINING\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for step in range(1,num_step+1):\n",
        "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
        "        sess.run(optimizer,feed_dict={X:batch_x,y:batch_y,keep_prob:0.8})\n",
        "        if step%display==0 or step==1:\n",
        "            loss,acc=sess.run([loss_op,accuracy],feed_dict={\n",
        "                X:batch_x,\n",
        "                y:batch_y,\n",
        "                keep_prob:1.0\n",
        "            })\n",
        "            print('loss ',loss)\n",
        "            print('acc ',acc)\n",
        "            \n",
        "        \n",
        "    print(\"ok.....\")\n",
        "    sess.run(accuracy,feed_dict={X:mnist.test.images[:256],\n",
        "                                 y:mnist.test.labels[:256],\n",
        "                                 keep_prob:1.0})\n",
        "    print('accuracy : ',accuracy)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Tensor(\"MaxPool_3:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-3-9a12459f2c22>:74: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "loss  453539070000.0\n",
            "acc  0.15625\n",
            "loss  472925960000.0\n",
            "acc  0.125\n",
            "loss  421911170000.0\n",
            "acc  0.09375\n",
            "ok.....\n",
            "accuracy :  Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}